{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e5a344d-1a20-4154-ab4f-b299cafdacac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from typing import Optional, Callable\n",
    "import os\n",
    "\n",
    "from scripts.loops import train_loop, valid_loop, test_loop\n",
    "from scripts.dataset_template import DatasetTemplate\n",
    "from scripts.models.autoencoder_cnn import CNNAutoencoder\n",
    "from scripts.models.autoencoder_lin import LinearAutoencoder\n",
    "from scripts.models.autoencoder_lstm import LSTMAutoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1109e6df-7b3f-483c-b4f1-02677901ba88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "#check if cuda available\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90f32ef8-9ff8-4929-81c0-fc1f009cf2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#paths\n",
    "data_train_path = \"/home/bolci/Documents/Projekty/5G_OPEN_RAN/Anomaly_detection/5G_Open_RAN/Data/Data_channels/train/comeretial\"\n",
    "data_test_folder_path = \"/home/bolci/Documents/Projekty/5G_OPEN_RAN/Anomaly_detection/5G_Open_RAN/Data/Data_channels/test\"\n",
    "data_valid_folder_path = \"/home/bolci/Documents/Projekty/5G_OPEN_RAN/Anomaly_detection/5G_Open_RAN/Data/Data_channels/valid\"\n",
    "\n",
    "testing_folders = os.listdir(data_test_folder_path)\n",
    "valid_folders = os.listdir(data_valid_folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3aac9aa5-eeb0-45ca-9e1c-e4689e0f3083",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameters\n",
    "batch_size = 1\n",
    "learning_rate = 0.01\n",
    "epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b8be78a-0a63-4848-98e6-0f56065c6b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#transforms\n",
    "data_transforms = transforms.Compose([transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0cfc522-2144-44aa-956f-43135ad0a945",
   "metadata": {},
   "outputs": [],
   "source": [
    "#datasets and dataloaders\n",
    "\n",
    "#train\n",
    "train_dataset = DatasetTemplate(data_train_path, 0, transform = data_transforms)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "#valid\n",
    "valid_datasets = {}\n",
    "valid_dataloaders = {}\n",
    "\n",
    "for valid_folder_name in valid_folders:\n",
    "    valid_folder_path_all = os.path.join(data_valid_folder_path, valid_folder_name)\n",
    "    valid_datasets[valid_folder_name] = DatasetTemplate(valid_folder_path_all, 1)\n",
    "    valid_dataloaders[valid_folder_name] = DataLoader(valid_datasets[valid_folder_name], batch_size=batch_size, shuffle=True)\n",
    "\n",
    "#test\n",
    "test_datasets = {}\n",
    "test_dataloaders = {}\n",
    "\n",
    "for test_folder_name in testing_folders:\n",
    "    test_folder_path_all = os.path.join(data_test_folder_path, test_folder_name)\n",
    "    test_datasets[test_folder_name] = DatasetTemplate(test_folder_path_all, 1)\n",
    "    test_dataloaders[test_folder_name] = DataLoader(test_datasets[test_folder_name], batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5724cdbb-b52e-47e2-9342-7f5acde27953",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Fake_Bts_PCI_466_wPA': <torch.utils.data.dataloader.DataLoader at 0x7f25600a21d0>,\n",
       " 'Fake_Bts_PCI_466': <torch.utils.data.dataloader.DataLoader at 0x7f25600a04f0>}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45719cd2-67b5-4492-ac8d-45f70ced9c4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid Error: \n",
      " Accuracy: 327.4010207312448%, Avg loss: 327.401021 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(327.4010207312448, 327.4010207312448)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#define model\n",
    "model = CNNAutoencoder().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "loss_RMS = lambda x,y: torch.sqrt(criterion(x, y))\n",
    "metric_fn_RMS = lambda x,y: torch.sqrt(criterion(x, y))\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "valid_loop(test_dataloaders[list(test_dataloaders.keys())[0]],\n",
    "          model,\n",
    "          loss_RMS,\n",
    "          metric_fn_RMS,\n",
    "          device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53a60e9b-0f59-4614-8b50-7c9f477698a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 171.045486  [    0/81710]\n",
      "\n",
      "loss: 94.782730  [10000/81710]\n",
      "\n",
      "loss: 85.276962  [20000/81710]\n",
      "\n",
      "loss: 327.691193  [30000/81710]\n",
      "\n",
      "loss: 101.895264  [40000/81710]\n",
      "\n",
      "loss: 74.863098  [50000/81710]\n",
      "\n",
      "loss: 88.736679  [60000/81710]\n",
      "\n",
      "loss: 100.333397  [70000/81710]\n",
      "\n",
      "loss: 248.940872  [80000/81710]\n",
      "\n",
      "valid Error: \n",
      " Accuracy: 708.2602741622925%, Avg loss: 708.260274 \n",
      "\n",
      "valid Error: \n",
      " Accuracy: 563.1163077139639%, Avg loss: 563.116308 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "#epochs\n",
    "\n",
    "# Lists to log the losses during the training process\n",
    "train_losses = []\n",
    "train_metrics = []\n",
    "\n",
    "valid_losses_true = []\n",
    "valid_metrics_true = []\n",
    "\n",
    "valid_losses_false = []\n",
    "valid_metrics_false = []\n",
    "\n",
    "for t in range(epochs):\n",
    "  print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "  train_loss, train_metric = train_loop(train_dataloader,\n",
    "                                     model,\n",
    "                                     loss_RMS,\n",
    "                                     optimizer)\n",
    "    \n",
    "  valid_loss_true, valid_metric_true = valid_loop(valid_dataloaders['Fake_Bts_PCI_466'],\n",
    "                                                  model,\n",
    "                                                  loss_RMS,\n",
    "                                                  metric_fn_RMS)\n",
    "\n",
    "  valid_loss_false, valid_metric_false = valid_loop(valid_dataloaders['Fake_Bts_PCI_466_wPA'],\n",
    "                                                    model,\n",
    "                                                    loss_RMS,\n",
    "                                                    metric_fn_RMS)\n",
    "    \n",
    "\n",
    "  train_losses.append(train_loss)\n",
    "  train_metrics.append(train_metric)\n",
    "\n",
    "  valid_losses_true.append(valid_loss_true)\n",
    "  valid_metrics_true.append(valid_metric_true)\n",
    "\n",
    "  valid_losses_false.append(valid_loss_false)\n",
    "  valid_metrics_false.append(valid_metric_false)\n",
    "    \n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2416dee9-e5c4-457c-8fe0-2c0e0681b3e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset name: Fake_Bts_PCI_466_wPA_traffic, mean_loss: 327.395322468816, mean_acc: 327.395322468816\n",
      "Dataset name: Fake_Bts_PCI_12, mean_loss: 448.14388313940015, mean_acc: 448.14388313940015\n",
      "Dataset name: Fake_Bts_PCI_466_traffic, mean_loss: 922.3986207925656, mean_acc: 922.3986207925656\n",
      "Dataset name: Fake_Bts_PCI_12_wPA, mean_loss: 537.0704357122285, mean_acc: 537.0704357122285\n"
     ]
    }
   ],
   "source": [
    "#testing\n",
    "\n",
    "for testing_name, testing_loader in test_dataloaders.items():\n",
    "    test_losses, test_metrics = test_loop(testing_loader, \n",
    "                                            model,\n",
    "                                            loss_RMS,\n",
    "                                             metric_fn_RMS)\n",
    "    mean_loss = np.mean(np.array(test_losses))\n",
    "    mean_metrics = np.mean(np.array(test_metrics))\n",
    "    print(f\"Dataset name: {testing_name}, mean_loss: {mean_loss}, mean_acc: {mean_metrics}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2deb13a7-b166-4e74-ab71-de78bc655870",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
